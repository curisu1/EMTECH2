{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpZtD1gMIhNEVSl/1vskXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curisu1/EMTECH2/blob/main/Finals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "e_jUJI2D6L0l",
        "outputId": "d73b994f-54c3-45bf-afd8-aaf41a61446f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SparseCategoricalCrossentropy.__init__() got an unexpected keyword argument 'fn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f4ff68947bf3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn_name\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mLossFunctionWrapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SparseCategoricalCrossentropy.__init__() got an unexpected keyword argument 'fn'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('cifar10_model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Image Classification App\")\n",
        "\n",
        "def label_class(class_number):\n",
        "    switch = {\n",
        "        0: \"Airplane\",\n",
        "        1: \"Automobile\",\n",
        "        2: \"Bird\",\n",
        "        3: \"Cat\",\n",
        "        4: \"Deer\",\n",
        "        5: \"Dog\",\n",
        "        6: \"Frog\",\n",
        "        7: \"Horse\",\n",
        "        8: \"Ship\",\n",
        "        9: \"Truck\",\n",
        "    }\n",
        "    return switch.get(class_number.numpy(), \"Invalid class number\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.title(\"Image Classification App\")\n",
        "    # Tooltips also support markdown\n",
        "    radio_markdown = '''\n",
        "    Upload an image, There are **limitations**!\n",
        "    '''.strip()\n",
        "    limit_expander = st.expander(\"**NOTICE**\", expanded=False)\n",
        "    with limit_expander:\n",
        "        st.caption('This **APP** is limited to classifying these images: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.')\n",
        "    # Upload an image through Streamlit\n",
        "    uploaded_file = st.file_uploader(\"Upload an image...\", type=[\"jpg\", \"jpeg\", \"png\"], help=radio_markdown)\n",
        "\n",
        "try:\n",
        "    if uploaded_file is not None:\n",
        "        # Preprocess the image\n",
        "        image = tf.keras.preprocessing.image.load_img(uploaded_file, target_size=(32, 32))\n",
        "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "        image_array = tf.expand_dims(image_array, 0)  # Create a batch\n",
        "\n",
        "        # Normalize the image (assuming the model was trained with normalized input)\n",
        "        image_array /= 255.0\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(image_array)\n",
        "        top_classes = tf.argsort(predictions[0], direction='DESCENDING')[:3]  # Display top 3 predictions\n",
        "        top_scores = tf.nn.softmax(predictions[0][top_classes])\n",
        "\n",
        "        # Display the results\n",
        "        # Display the highest confidence prediction\n",
        "        highest_confidence_idx = top_classes[0]\n",
        "        highest_confidence_label = label_class(highest_confidence_idx)\n",
        "        highest_confidence_score = 100 * top_scores[0].numpy()\n",
        "        st.write(f\"Highest Confidence: Class {highest_confidence_label}, Confidence: {highest_confidence_score:.2f}%\")\n",
        "\n",
        "        st.write(\"Top Predictions:\")\n",
        "        for i, (class_idx, score) in enumerate(zip(top_classes, top_scores)):\n",
        "            class_label = label_class(class_idx)\n",
        "            st.write(f\"{i + 1}. Class: {class_label}, Confidence: {100 * score:.2f}%\")\n",
        "        st.image(image, caption=\"Uploaded Image\", use_column_width=True, width=300)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    st.write(\"An error occurred:\", str(e))"
      ]
    }
  ]
}